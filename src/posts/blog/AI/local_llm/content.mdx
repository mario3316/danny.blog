---
title: "로컬에서 LLM 실행하기"
date: 2024-08-28
description: LLM(대규모 언어 모델)을 로컬 환경에서 실행하는 방법을 알아보겠습니다.
thumbnail: /blog/posts/AI/local_llm/thumbnail.png
---

## LLM
LLM(Large-Language-Model)은 방대한 양의 데이터로 사전 학습된 딥러닝 모델을 의미합니다. GPT-4o, Claude 등등이 이에 해당합니다.
이러한 방대한 양의 데이터를 바탕으로 LLM은 사용자의 프롬프트 입력을 기반으로 질문에 답하고, 문서를 요약하는 등 다양한 곳에 사용될 수 있습니다.

이번 포스팅에서는 로컬 환경에서 LLM을 구동할 수 있는 오픈소스 소프트웨어인 Ollama와 그 사용법에 대해 알아보겠습니다.

## Ollama
Ollama는 로컬 환경에서 LLM을 구동할 수 있게 해주는 오픈소스 소프트웨어 입니다. llama3.1, gemma2, mistral 등 다양한 오픈소스 LLM 모델을 지원합니다.
모델들은 [이곳](https://ollama.com/library)에서 받아볼 수 있습니다.

## 사용 방법
**1. [Ollama 설치](https://ollama.com/download)**
현재 macOS, Linux, Windows 모두 지원합니다. (Windows는 Preview 버전) 자신의 OS 환경에 맞게 설치해주면 되겠습니다.
![모델 선택하기](/blog/posts/AI/local_llm/imgs/1.png)

**2. 설치가 완료되면 프롬프트 창에서 원하는 모델을 다운받습니다.**
`ollama run llama3.1`을 입력하면 자동으로 다운받고 실행까지 됩니다.
![프롬프트 화면](/blog/posts/AI/local_llm/imgs/2.png)



## 커스텀 모델 사용해보기
HuggingFace(https://huggingface.co/)는 AI 모델 커뮤니티로, 다양한 오픈소스 LLM 커스텀 모델을 제공합니다. 여기서 원하는 커스텀 모델을 받아 설치하고 사용하는 방법을 알아보겠습니다.
예시로 teddylee777님의 Llama-3-Open-Ko-8B-gguf 모델을 받아보도록 하겠습니다.

![커스텀 모델 다운받기](/blog/posts/AI/local_llm/imgs/3.png)

Files and versions에서 모델 파일을 받을 수 있습니다. 

![](/blog/posts/AI/local_llm/imgs/4.png)
모델을 다운받고, 같은 디렉토리에 위의 내용으로 `Modelfile` 이란 파일을 작성해줍니다. 편집기를 통해 위의 내용을 붙여넣고 확장자없이 이름을 `Modelfile`로 저장해주면 됩니다.


![커스텀 모델 설치](/blog/posts/AI/local_llm/imgs/5.png)
프롬프트로 모델이 저장된 위치로 이동한 뒤, 명령어를 입력해주면 정상적으로 모델을 설치하는 것을 볼 수 있습니다.
`ollama create [Modelname] -f Modelfile`
Modelname은 본인이 원하는 대로 작성해주면 됩니다.

이후 똑같이 `ollama run [Modelname]`으로 커스텀 LLM 모델을 실행해볼 수 있습니다.

## 참고 문서
https://aws.amazon.com/ko/what-is/large-language-model/
https://brunch.co.kr/@b2439ea8fc654b8/24
https://www.gpters.org/dev/post/ollama-2-chatgpt-local-t36UQuUtkXOxQrd
https://brunch.co.kr/@b2439ea8fc654b8/28